---
title: "Keyword landscape analysis"
author: ""
date: "Last updated on `r Sys.Date()`"
output:
  html_document:
    theme: paper
    highlight: kate
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: true
editor_options: 
  chunk_output_type: inline
---


<style>
.list-group-item.active, .list-group-item.active:hover, .list-group-item.active:focus {
  background-color: #00d188;
  border-color: #00d188;
}

body {
  font-family: montserrat;
  color: #444444;
  font-size: 14px;
}

h1 {
  font-weight: bold;
  font-size: 28px;
}

h1.title {
  font-size: 30px;
  color: #00d188;
}

h2 {
  font-size: 24px;
}

h3 {
  font-size: 18px;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = F, message = F, fig.path = "../plots/", cache = F, fig.showtext = TRUE, dpi = 700)
knitr::knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark = ",", small.mark = ",", scientific = F)
})
Sys.setlocale("LC_TIME", "C")
extrafont::loadfonts(device = "win")
```



```{r prep}
set.seed(1)
required_packages <- c("tidyverse", "magrittr", "DBI", "bigrquery", "arrow","glue", "vroom","janitor", "gt", "ggwordcloud", "readxl", "ggthemes", "hrbrthemes", "extrafont", "plotly", "scales", "stringr", "gganimate", "here", "tidytext", "sentimentr", "scales", "DT", "here", "sm", "mblm", "glue", "fs", "knitr", "rmdformats", "janitor", "urltools", "colorspace", "pdftools", "showtext", "pander", "wordcloud2", "stopwords", "magicfor", "gapminder")
for(i in required_packages) { 
  if(!require(i, character.only = T)) {
    #  if package is not existing, install then load the package
    install.packages(i, dependencies = T)
  require(i, character.only = T)
  }
}
panderOptions('table.alignment.default', "left")
## quality of png's
dpi <- 750
## theme updates; please adjust to clientÂ´s website
#theme_set(ggthemes::theme_clean(base_size = 15))
theme_set(ggthemes::theme_clean(base_size = 15, base_family = "Montserrat"))
theme_update(plot.margin = margin(30, 30, 30, 30),
             plot.background = element_rect(color = "white",
                                            fill = "white"),
             plot.title = element_text(size = 20,
                                       face = "bold",
                                       lineheight = 1.05,
                                       hjust = .5,
                                       margin = margin(10, 0, 25, 0)),
             plot.title.position = "plot",
             plot.caption = element_text(color = "grey40",
                                         size = 9,
                                         margin = margin(20, 0, -20, 0)),
             plot.caption.position = "plot",
             axis.line.x = element_line(color = "black",
                                        size = .8),
             axis.line.y = element_line(color = "black",
                                        size = .8),
             axis.title.x = element_text(size = 16,
                                         face = "bold",
                                         margin = margin(t = 20)),
             axis.title.y = element_text(size = 16,
                                         face = "bold",
                                         margin = margin(r = 20)),
             axis.text = element_text(size = 11,
                                      color = "black",
                                      face = "bold"),
             axis.text.x = element_text(margin = margin(t = 10)),
             axis.text.y = element_text(margin = margin(r = 10)),
             axis.ticks = element_blank(),
             panel.grid.major.x = element_line(size = .6,
                                               color = "#eaeaea",
                                               linetype = "solid"),
             panel.grid.major.y = element_line(size = .6,
                                               color = "#eaeaea",
                                               linetype = "solid"),
             panel.grid.minor.x = element_line(size = .6,
                                               color = "#eaeaea",
                                               linetype = "solid"),
             panel.grid.minor.y = element_blank(),
             panel.spacing.x = unit(4, "lines"),
             panel.spacing.y = unit(2, "lines"),
             legend.position = "top",
             legend.title = element_text(family = "Montserrat",
                                         color = "black",
                                         size = 14,
                                         margin = margin(5, 0, 5, 0)),
             legend.text = element_text(family = "Montserrat",
                                        color = "black",
                                        size = 11,
                                        margin = margin(4.5, 4.5, 4.5, 4.5)),
             legend.background = element_rect(fill = NA,
                                              color = NA),
             legend.key = element_rect(color = NA, fill = NA),
             #legend.key.width = unit(5, "lines"),
             #legend.spacing.x = unit(.05, "pt"),
             #legend.spacing.y = unit(.55, "pt"),
             #legend.margin = margin(0, 0, 10, 0),
             strip.text = element_text(face = "bold",
                                       margin = margin(b = 10)))
## theme settings for flipped plots
theme_flip <-
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_line(size = .6,
                                          color = "#eaeaea"))
## theme settings for charts without y axis
theme_blank <- 
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        axis.line.y = element_blank(),
        axis.text.y = element_blank())

## numeric format for labels
num_format <- scales::format_format(big.mark = ",", small.mark = ",", scientific = F)
## main color backlinko
bl_col <- "#00d188"
bl_dark <- darken(bl_col, .3, space = "HLS")
```


```{r common_functions}
display_number <- function(n, title){
  tibble(!!sym(title) := format(n, big.mark = ",")) %>% pander()
}
```


```{r, cache}
con <- dbConnect(
    bigrquery::bigquery(),
    project = "dataforseo-bigquery",
    billing = "dataforseo-bigquery"
)
sql <- glue("SELECT * FROM `dataforseo-bigquery.dataforseo_data.keyword_data` 
          WHERE location = 2840 
          AND keyword_info_search_volume > 0
          ORDER BY keyword_info_search_volume DESC
          LIMIT 50000")
tb <- bq_project_query("dataforseo-bigquery", sql)
top <- bq_table_download(tb, max_results = 50000)
```


!!!J: In this version I remove all the entries with zero volume for all stats. I think if we prefer to go by count rather than by volume, this is the best approach.

!!!D: Sounds good. I trust you on this. Please make sure to add a note to the methodology section when moving the files. 



# Basic stats

```{sql, connection = con, output.var = "sql"}
SELECT COUNT(keyword_info_search_volume) as total_count
FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
WHERE `location` = 2840
AND keyword_info_search_volume > 0
```



```{r}
total_count <- sql$total_count
tibble("Total number of searches" = glue("~{format(round(total_count / 1000000))} million")) %>% 
  pander()
```


```{sql, connection = con, output.var = "sql"}
SELECT SUM(COALESCE(keyword_info_search_volume / 10000, 0)) AS total_volume
FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
WHERE location = 2840
```


```{r}
# Calculated in a roundabout way to avoid integer overflow
total_volume <- sql$total_volume * 10000
tibble("Total volume of searches" = glue("~{format(round(total_volume / 1000000000))} billion")) %>% 
  pander()
```


<br>

This table shows the top 10 searches. They are all spelling errors. As in, they are not really searched, but rather people attempting to go to Youtube or Facebook, but typing it wrong. Oddly they are all attributed as having a search volume of exactly 185 million.

```{r}
tbl <- top %>% 
  select(keyword, location, spell, spell_type, keyword_info_search_volume) %>% 
  head(10)

tbl %>% write_csv("../plots/csv/top_misspell.csv")

tbl %>% gt() %>% 
  tab_options(table.align = "left") %>% 
  tab_header("Top searches")
```

```{sql, connection = con, output.var = "sql"}
SELECT COUNT(*) as missing_count
FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
WHERE `location` = 2840
AND keyword_info_search_volume IS NULL
```

```{r}
missing_count <- sql$missing_count
tibble("Missing search volume" = scales::percent(missing_count / total_count, accuracy = 0.001)) %>% pander()
```

The missing have some searches that are likely high volume. Thus they are truly missing, and not just 0s.

```{sql, connection = con, output.var = "sql"}
SELECT keyword, keyword_info_search_volume
FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
WHERE `location` = 2840
AND keyword_info_search_volume IS NULL
ORDER BY RAND()
LIMIT 10
```

```{r}
sql %>% gt() %>% tab_options(table.align = "left") %>% 
  tab_header("Keywords with missing search volume")
```


```{r}
display_number(total_volume / total_count, "Mean search volume")
```


```{sql, connection = con, output.var = "sql"}
SELECT approx_quantiles(keyword_info_search_volume, 2)[offset(1)] AS median
FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
WHERE location = 2840
AND keyword_info_search_volume > 0
```


```{r}
display_number(sql$median, "Median search volume")
```


```{sql, connection = con, output.var = "sql"}
SELECT AVG(`keyword_info_cpc`) AS mean_cpc
FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
WHERE `location` = 2840
AND keyword_info_search_volume > 0
```


```{r}
display_number(sql$mean_cpc, "Mean CPC")
```


```{sql, connection = con, output.var = "sql"}
SELECT approx_quantiles(keyword_info_cpc, 2)[offset(1)] AS median_cpc
FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
WHERE location = 2840
AND keyword_info_search_volume > 0
```


```{r}
display_number(sql$median_cpc, "Median CPC")
```

<br>

# Spell types


```{sql, connection = con, output.var = "sql"}
SELECT spell_type, SUM(keyword_info_search_volume) / 10000 AS `volume`
FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
WHERE location = 2840
GROUP BY spell_type
```

```{r spell_types_volume, fig.width = 9}
spell_types <- sql %>% 
  mutate(spell_type = case_when(
    spell_type == "" ~ "No spell type",
    spell_type == "showing_results_for" ~ "Showing results for",
    spell_type == "did_you_mean" ~ "Did you mean",
    spell_type == "no_results_found_for" ~ "No results found for")) %>% 
  mutate(volume = volume / sum(volume))

spell_types %>% ggplot(aes(x = reorder(spell_type, volume), y = volume)) +
  geom_bar(stat = "identity", width = 0.8, fill = "turquoise4", color = "black") +
  labs(x = "", y = "", title = "Spell types - by volume") +
  scale_y_continuous(labels = scales::percent)
```


<br>

About half of search volume has a spell type. This is especially driven by misspellings of common domains. 

If going by count instead of by volume, almost none of the searches have a spell type:

```{sql, connection = con, output.var = "sql"}
SELECT spell_type, COUNT(spell_type) as n
FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
WHERE location = 2840
ANd keyword_info_search_volume > 0
GROUP BY spell_type
```

```{r}
prop <- 1 - sql %>% filter(spell_type == "") %>% pull(n) / total_count
tibble("Proportion with spell type" = scales::percent(prop, accuracy = 0.001)) %>% pander()
```


```{r spell_types_count}
spell_types <- sql %>% 
  filter(spell_type != "") %>% 
  mutate(spell_type = case_when(
    spell_type == "" ~ "No spell type",
    spell_type == "showing_results_for" ~ "Showing results for",
    spell_type == "did_you_mean" ~ "Did you mean",
    spell_type == "no_results_found_for" ~ "No results found for"))

spell_types %>% mutate(prop = n / sum(n)) %>% 
  ggplot(aes(x = reorder(spell_type, prop), y = prop)) +
  geom_bar(stat = "identity", width = 0.8, fill = "turquoise4", color = "black") +
  labs(x = "", y = "", title = "Spell types - by count") +
  scale_y_continuous(labels = scales::percent)
```


!!!D: without spell type is missing "No spell type"

!!!J: This is on purpose, since only 1.38% has a spell type, as shown just above.

<br>


```{r}
tbl <- top %>% group_by(spell) %>% 
  summarise(volume = sum(keyword_info_search_volume)) %>% 
  arrange(desc(volume)) %>% 
  filter(spell != "") %>% 
  mutate(volume = scales::percent(volume / sum(volume), accuracy = 0.1)) %>% 
  head(10)# 

tbl %>% write_csv("../plots/csv/misspell.csv")

tbl %>% 
  gt() %>% 
  tab_options(table.align = "left") %>% 
  tab_header("Top 10 intended searches that are misspelled")
```


<br>
<br>

# Questions


```{r questions_volume}
question_words <- c("what", "which", "where", "who", "why", "how")
write_questions_volume <- function(){
  questions <- tribble(~question, ~volume)
  for (word in question_words){
    sql <- glue("SELECT sum(keyword_info_search_volume) FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
              WHERE location = 2840 
              AND keyword like '% {word} %' OR keyword like '{word} %' OR keyword like '% {word}'")
    tb <- bq_project_query("dataforseo-bigquery", sql)
    df <- bq_table_download(tb) 
    questions %<>% add_row(question = word, volume = df$f0_)
  }
  write_csv(questions, "../proc_data/questions_volume.csv")
}
#write_questions_volume()
questions <- read_csv("../proc_data/questions_volume.csv")

questions %>% mutate(prop = volume / total_volume) %>% 
  ggplot(aes(x = reorder(question, prop), y = prop)) +
  geom_bar(stat = "identity", fill = bl_dark, color = "black") +
  geom_text(aes(label = glue::glue("{format(round(prop, 4) * 100, scientific = FALSE)}%")),
            nudge_y = .0002, family = "Montserrat", fontface = "bold", color = "grey40") +
  scale_x_discrete(expand = c(.12, .12)) +
  scale_y_continuous(#labels = scales::label_percent(accuracy = 1), 
                     #breaks = seq(0, .5, by = .1),
                     expand = c(0, 0),
                     limits = c(0, .0054)) +
  labs(title = "Questions in searches - by volume", x = NULL, y = NULL) +
  theme_blank + 
  theme(plot.title = element_text(margin = margin(b = 7))) +
  ggsave(here::here("plots", "reworked", "questions_volume.pdf"),
         width = 10, height = 6, device = cairo_pdf)
    
```


```{r questions_count}
write_questions_count <- function(){
  questions <- tribble(~question, ~n)
  for (word in question_words){
    sql <- glue("SELECT COUNT(keyword_info_search_volume) as n
              FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
              WHERE location = 2840
              AND keyword_info_search_volume > 0
              AND keyword like '% {word} %' OR keyword like '{word} %' OR keyword like '% {word}'")
    tb <- bq_project_query("dataforseo-bigquery", sql)
    df <- bq_table_download(tb) 
    questions %<>% add_row(question = word, n = df$n)
  }  
  write_csv(questions, "../proc_data/questions_count.csv")
}
#write_questions_count()
questions <- read_csv("../proc_data/questions_count.csv")
questions %>% mutate(prop = n / total_count) %>% 
  ggplot(aes(x = reorder(question, prop), y = prop)) +
  geom_bar(stat = "identity", fill = bl_dark, color = "black") +
  geom_text(aes(label = glue::glue("{format(round(prop, 4) * 100, scientific = FALSE)}%")),
            nudge_y = .0025, family = "Montserrat", fontface = "bold", color = "grey40") +
  scale_x_discrete(expand = c(.12, .12)) +
  scale_y_continuous(#labels = scales::label_percent(accuracy = 1), 
                     #breaks = seq(0, .5, by = .1),
                     expand = c(0, 0),
                     limits = c(0, .085)) +
  labs(title = "Questions in searches - by count", x = NULL, y = NULL) +
  theme_blank + 
  theme(plot.title = element_text(margin = margin(b = 7))) +
  ggsave(here::here("plots", "reworked", "questions_count.pdf"),
         width = 10, height = 6, device = cairo_pdf)
```



```{r}
tibble("Total percentage of searches that are questions" = 
         scales::percent(questions %$% sum(n) / total_count, accuracy = 0.001)) %>% 
  pander()
```

<br>

# Stopwords

```{r stopwords_count, fig.height = 6, fig.width = 6}
stopword_list <- tibble(stopword = stopwords::stopwords(language = "en")) %>% 
  mutate(stopword = str_remove(stopword, "'")) %>% 
  filter(!(stopword %in% c("shed", "wed", "ill", "hell", "shell")))
get_stopwords_counts <- function(){
  stopwords <- tribble(~stopword, ~n)
    for (word in stopword_list$stopword){
      print(word)
      sql <- glue(
        "SELECT COUNT(keyword_info_search_volume) AS stopword_count
         FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
         WHERE location = 2840 
         AND keyword_info_search_volume > 0
         AND keyword like '% {word} %' OR keyword like '{word} %' OR keyword like '% {word}'")
      tb <- bq_project_query("dataforseo-bigquery", sql)
    
      df <- bq_table_download(tb) 
      stopwords %<>% add_row(stopword = word, n = df$stopword_count)
    }
    
    write_csv(stopwords, "../proc_data/stopwords.csv")
}
#get_stopwords_counts()
stopwords <- read_csv("../proc_data/stopwords.csv")
stopwords %>% mutate(prop = n / total_count) %>%
  arrange(desc(prop)) %>% 
  head(10) %>% 
  ggplot(aes(x = reorder(stopword, prop), y = prop)) +
  geom_bar(stat = "identity", color = "black", fill = "turquoise4", width = 0.7) +
  scale_y_continuous(labels = scales::percent, expand = c(0,0), limits = c(0, 0.085)) +
  labs(x = NULL, y = NULL, title = "Searches with specific stopwords") +
  coord_flip()
```



!!!D: the graph is not that insightful. Please make the wordcloud a bit more readable and visually appealing. Feel to add more than 25 words. 




```{r wordcloud, fig.width = 10, fig.height = 7.5}
s2 <- stopwords %>% mutate(n = sqrt(n)) %>% arrange(-n)

#wordcloud2(s2, size = 0.6, gridSize = 15, minSize = 10,
#           fontFamily = "Montserrat", color = bl_col)

ggplot(s2, aes(label = stopword, size = n, color = n)) +
    geom_text_wordcloud(
      family = "Montserrat",
      fontface = "bold",
      shape = "circle",
      grid_margin = 2.5,
      seed = 1
    ) +
    #scale_color_gradient(low = "grey85", high = bl_dark) +
    scico::scale_color_scico(palette = "batlow", direction = -1) +
    scale_size_area(max_size = 25) +
    theme_void()

ggsave(here::here("plots", "reworked", "stopwords_cloud_colors.png"),
       width = 10, height = 7.5)
```


<br>

# Search tails


```{r search_tails, fig.width = 10, fig.height = 6}
volume_top <- top %>%  
  add_rownames() %>% 
  mutate(rowname = as.numeric(rowname)) %>% 
  select(rowname, volume = keyword_info_search_volume)
ylab <- c(50, 100, 150, 200)
volume_top %>% 
  filter(rowname < 10000) %>% 
  mutate(cat = case_when(
    rowname < 500 ~ "Top 500",
    rowname < 2000 ~ "Top 2000",
    rowname < 10000 ~ "Top 10000"
  )) %>% 
  mutate(cat = factor(cat, levels = c("Top 500", "Top 2000", "Top 10000"))) %>% 
  head(10500) %>% 
  ggplot(aes(x = rowname, y = volume, fill = cat)) +
  geom_area(alpha = 0.8) +
  scale_y_continuous(
    labels = glue("{ylab} M"),
    breaks = 10^6 * ylab,
    limits = c(0, 200* 10^6), 
    expand = c(.001, .001)
    ) +
  labs(x = NULL, title = "Volume of searches", fill = "") + 
  annotate("text", x = 9000, y = 65*10^6, label = "Remaining\n99.9967%", family = "Montserrat") + 
  geom_segment(aes(x = 7900, y = 42*10^6, xend = 10000, yend = 42*10^6),
               arrow = arrow(length = unit(0.35, "cm"), type = "closed")) +
  scale_x_continuous(expand = c(.001, .001), limits = c(0, 10000)) +
  scale_fill_manual(values = c(bl_dark, bl_col, "grey75")) +
  theme(axis.text.x = element_blank()) +
  ggsave(here::here("plots", "reworked", "volume_by_searches.pdf"),
         width = 10, height = 6, device = cairo_pdf)
```

<br>

```{r search_tails2}
get_count_range <-  function(lower, higher)
{
  sql <- glue(
        "SELECT COUNT(*) AS `count` 
         FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
         WHERE location = 2840 
         AND keyword_info_search_volume >= {lower} 
         AND keyword_info_search_volume <= {higher}")
      tb <- bq_project_query("dataforseo-bigquery", sql)
      bq_table_download(tb)$count
}
df <- tribble(
  ~cat, ~count,
  "0 - 10", get_count_range(0, 10),
  "11- 100", get_count_range(11, 100),
  "101 - 1000", get_count_range(101, 1000),
  "1001 - 10000", get_count_range(1001, 10000),
  "10001 - 100000", get_count_range(10001, "100000"),
  "100001+", get_count_range("100001", "100000000000")) 
df %>% 
  mutate(count = count / sum(count)) %>% 
  ggplot(aes(x = reorder(cat, desc(count)), y = count)) +
  geom_bar(stat = "identity", fill = bl_dark, color = "black", width = .85) +
  geom_text(aes(label = glue::glue("{format(round(count, 4) * 100, scientific = FALSE)}%")),
            nudge_y = .025, family = "Montserrat", fontface = "bold", color = "grey40", size = 3) +
  theme(panel.grid.major.x = element_blank()) +
  labs(x = "Volume", y = "Percentage of all searches", title = "Volume of searches") +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1), expand = c(.01, .01)) +
  ggsave(here::here("plots", "reworked", "volume_percentage.pdf"),
         width = 10, height = 6, device = cairo_pdf)
```

<br>



# Keyword length

```{r}
write_length_volume <- function()
{
  get_length_volume <-  function(l)
  {
    sql <- glue(
          "SELECT sum(keyword_info_search_volume) / 10000 as `volume`, count(keyword_info_search_volume) as `count`
           FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
           WHERE location = 2840
           AND keyword_info_search_volume IS NOT NULL
           AND LENGTH(keyword) = {l}")
        tb <- bq_project_query("dataforseo-bigquery", sql)
        bq_table_download(tb) %>% mutate(length = l, volume = volume * 10000)
  }
  
  df <- map_df(1:50, get_length_volume)  
  write_csv(df, "../proc_data/keyword_length_volume.csv")
}
```


```{r keyword_length_volume, fig.width = 10, fig.height = 6}
df <- read_csv("../proc_data/keyword_length_volume.csv")
df %>% mutate(prop = volume / sum(volume)) %>% 
  ggplot(aes(x = length, y = prop)) +
  geom_line(color = colorspace::desaturate(bl_col, .35), size = 1) + 
  geom_point(color = bl_dark, size = 2.5) +
  scale_x_continuous(expand = c(.008, .008)) +
  scale_y_continuous(labels = scales::label_percent(accuracy = 1), breaks = seq(0, .14, by = .02)) +
  labs(x = "Keyword length", y = "Total search volume", title = "Search volume by keyword length") +
  theme(panel.grid.minor.x = element_blank()) +
  ggsave(here::here("plots", "reworked", "volume_keywordlength.pdf"),
         width = 10, height = 6, device = cairo_pdf)
```
The most searched queries have length 6-9 characters, and falls continuously for search queries longer or shorter than that.



<br>


# Keyword_info categories

```{r}
pservices <- read_csv("../raw_data/productsservices.csv") %>% 
  clean_names() %>% rename(c1 = criterion_id) %>% select(-category) %>% 
  separate(c1, sep =",\"", into = c("id", "category")) %>% 
  mutate(category = substr(category, 2, nchar(category) -1)) %>% 
  separate(category, sep = "/", into = c("cat1", "cat2", "cat3", "cat4", "cat5", "cat6", "cat7", "cat8"))
toplevel <- pservices %>% filter(is.na(cat2))
```



```{r}
write_categories <- function()
{
  get_category_volume <-  function(id){
    sql <- glue(
      "SELECT SUM(keyword_info_search_volume) / 10000 AS `search_volume`, AVG(keyword_info_cpc) AS `cpc`, COUNT(*) AS `count`
       FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
       WHERE location = 2840 
       AND keyword_info_categories like '%{id}%' ")
    tb <- bq_project_query("dataforseo-bigquery", sql)
    bq_table_download(tb) %>% mutate(id = id)
  }
  df <- map_df(toplevel$id, get_category_volume)  
  
  df %>% mutate(search_volume = search_volume * 10000,
                mean_volume = search_volume / count
                ) %>% 
    left_join(toplevel %>% select(id, cat1), by = "id") %>% 
    write_csv("../proc_data/categories_averages.csv")
}
df <- read_csv("../proc_data/categories_averages.csv")
```


```{r search_category_volume_mean, fig.height = 10, fig.width = 7.5}
df %>% 
  ggplot(aes(x = fct_rev(cat1), y = mean_volume)) +
  geom_bar(stat = "identity", fill = bl_dark, width = 0.7) +
  coord_flip() + 
  theme_flip +
  theme(panel.grid.major.y = element_blank(), axis.line.y = element_blank()) +
  scale_y_continuous(limits = c(0, 9000), expand = c(0,0), breaks = seq(0, 8000, by = 2000)) +
  labs(x = NULL, y = NULL, title = "Search volume mean by category") +
  ggsave(here::here("plots", "reworked", "volume_category.pdf"),
         width = 10, height = 7.5, device = cairo_pdf)

df %>% 
  ggplot(aes(x = fct_reorder(cat1, mean_volume), y = mean_volume)) +
  geom_bar(stat = "identity", fill = bl_dark, width = 0.7) +
  coord_flip() + 
  theme_flip +
  theme(panel.grid.major.y = element_blank(), axis.line.y = element_blank()) +
  scale_y_continuous(limits = c(0, 9000), expand = c(0,0), breaks = seq(0, 8000, by = 2000)) +
  labs(x = NULL, y = NULL, title = "Search volume mean by category") +
  ggsave(here::here("plots", "reworked", "volume_category_ordered.pdf"),
         width = 10, height = 7.5, device = cairo_pdf)
```

!!!D: I would be curious to see the same graph with median. WouldnÂ´t it be better to use median given the skewed data set? 

!!!J: I am skeptical for using the median, since it is brought far down by a large number of searches with low volume, even when we exclude 0 volume searches. Remember, the median cpc overall was 0. But you are right that it is an issue with the skewed data set.

!!!D: Maybe a boxplot or something similiar would make more sense here? Or something like that: https://tinyurl.com/yxfwo5vt Leave that out if itÂ´s too complicated to implement.  


```{r}
write_categories_volume <- function()
{
  get_category_volume <-  function(id){
    sql <- glue(
      "SELECT SUM(keyword_info_search_volume) / 10000 as volume
       FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
       WHERE location = 2840 
       AND keyword_info_search_volume > 0
       AND keyword_info_categories like '%{id}%' ")
    tb <- bq_project_query("dataforseo-bigquery", sql)
    bq_table_download(tb) %>% mutate(id = id)
  }
  df <- map_df(toplevel$id, get_category_volume) %>% 
    mutate(volume = volume * 10000)
  
  df %>% left_join(toplevel %>% select(id, cat1), by = "id") %>% 
    write_csv("../proc_data/categories_total_volume.csv")
}
write_categories_volume()
df <- read_csv("../proc_data/categories_total_volume.csv")
```

<br>

```{r search_category_total_volume, fig.height = 10, fig.width = 7.5}
df %>% 
  mutate(volume = volume / sum(volume)) %>% 
  ggplot(aes(x = fct_rev(cat1), y = volume)) +
  geom_bar(stat = "identity", fill = bl_dark, width = 0.7) +
  coord_flip() + 
  theme_flip +
  theme(panel.grid.major.y = element_blank(), axis.line.y = element_blank()) +
  scale_y_continuous(limits = c(0, .2), expand = c(0,0)) +
  labs(x = NULL, y = NULL, title = "Total search volume by category") +
  ggsave(here::here("plots", "reworked", "volume_total_category.pdf"),
         width = 10, height = 7.5, device = cairo_pdf)

df %>% 
  mutate(volume = volume / sum(volume)) %>% 
  ggplot(aes(x = fct_reorder(cat1, volume), y = volume)) +
  geom_bar(stat = "identity", fill = bl_dark, width = 0.7) +
  coord_flip() + 
  theme_flip +
  theme(panel.grid.major.y = element_blank(), axis.line.y = element_blank()) +
  scale_y_continuous(limits = c(0, .2), expand = c(0,0)) +
  labs(x = NULL, y = NULL, title = "Total search volume by category") +
  ggsave(here::here("plots", "reworked", "volume_total_category_ordered.pdf"),
         width = 10, height = 7.5, device = cairo_pdf)
```

<br>

```{r}
write_categories <- function()
{
  get_category <-  function(id){
    sql <- glue(
      "SELECT AVG(keyword_info_cpc) as mean_cpc
       FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
       WHERE location = 2840 
       AND keyword_info_search_volume > 0
       AND keyword_info_categories like '%{id}%' ")
    tb <- bq_project_query("dataforseo-bigquery", sql)
    bq_table_download(tb) %>% mutate(id = id)
  }
  df <- map_df(toplevel$id, get_category)  
  
  df %>% left_join(toplevel %>% select(id, cat1), by = "id") %>% 
    write_csv("../proc_data/categories_cpc.csv")
}
write_categories()
df <- read_csv("../proc_data/categories_cpc.csv")
```

<br>

```{r search_category_cpc_mean, fig.height = 10, fig.width = 6.5}
df %>% 
  ggplot(aes(x = fct_rev(cat1), y = mean_cpc)) +
  geom_bar(stat = "identity", fill = bl_dark, width = 0.7) +
  coord_flip() + 
  theme_flip +
  theme(panel.grid.major.y = element_blank(), axis.line.y = element_blank()) +
  scale_y_continuous(limits = c(0, 2), expand = c(0,0)) +
  labs(x = NULL, y = NULL, title = "Mean CPC by category") +
  ggsave(here::here("plots", "reworked", "cpc_mean_category.pdf"),
         width = 10, height = 6.5, device = cairo_pdf)

df %>% 
  ggplot(aes(x = fct_reorder(cat1, mean_cpc), y = mean_cpc)) +
  geom_bar(stat = "identity", fill = bl_dark, width = 0.7) +
  coord_flip() + 
  theme_flip +
  theme(panel.grid.major.y = element_blank(), axis.line.y = element_blank()) +
  scale_y_continuous(limits = c(0, 2), expand = c(0,0)) +
  labs(x = NULL, y = NULL, title = "Mean CPC by category") +
  ggsave(here::here("plots", "reworked", "cpc_mean_category_ordered.pdf"),
         width = 10, height = 6.5, device = cairo_pdf)
```

<br>

# Keyword type


```{r keyword_words_count}
transactional_words <- c("apply", "buy", "coupons", "clearance", "deals", "discount",
                         "download", "for sale", "order", "purchase", "reserve",
                         "schedule appointment", "special")

informational_words <- c("how do", "how does", "how can i", "what is", "what are", "ways to", "guide", 
                         "how to", "tutorial", "best", "cheap", "alternatives", "compare", "improve")

navigational_words <- c("location of", "near me", "features of", "cost of", "hours of", "directions to",
                        "reviews", "free shipping", "prices", "testimonials")

get_keyword_counts <- function(type, wordlist){
  words <- tribble(~keyword, ~n)
  for (word in wordlist){
    print(word)
    sql <- glue(
      "SELECT COUNT(keyword_info_search_volume) AS count
       FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
       WHERE location = 2840 
       AND keyword_info_search_volume > 0
       AND keyword like '% {word} %' OR keyword like '{word} %' OR keyword like '% {word}'")
    tb <- bq_project_query("dataforseo-bigquery", sql)
  
    df <- bq_table_download(tb) 
    words %<>% add_row(keyword = word, n = df$count)
  }
  write_csv(words %>% mutate(type = type), glue("../proc_data/{type}_words.csv"))
}


#get_keyword_counts("transactional", transactional_words)
#get_keyword_counts("informational", informational_words)
#get_keyword_counts("navigational", navigational_words)

df <- bind_rows(
  read_csv("../proc_data/transactional_words.csv"),
  read_csv("../proc_data/informational_words.csv"),
  read_csv("../proc_data/navigational_words.csv")
)

df %>% group_by(type) %>% 
  summarise(prop = sum(n) / total_count) %>% 
  mutate(type = str_to_title(type)) %>% 
  ggplot(aes(x = type, y = prop)) +
  geom_bar(stat = "identity", width = 0.8, fill = "turquoise4", color = "black") +
  scale_y_continuous(labels = scales::percent, limits = c(0, 0.13), expand = c(0,0)) +
  labs("Keyword type", y = NULL, x = NULL)

```





## Other countries


```{r}
loc <- jsonlite::read_json("../raw_data/locations_stats.json")

magic_for(print, silent = TRUE)
for (i in 1:67){
    country <- loc$tasks[[1]]$result[[i]]$location_name
    code <- loc$tasks[[1]]$result[[i]]$location_code
    
    print(country)
    print(code)
}

countries <- magic_result_as_dataframe() %>% 
    left_join(
        gapminder %>% 
            filter(year == 2007),
        by = "country")
```




```{r}
write_locations_cpc <- function(){
    magic_for(print, silent = TRUE)
    for (code in countries$code){
        sql <- glue("SELECT AVG(keyword_info_cpc) as cpc
                    FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
                  WHERE location = {code} 
                  AND keyword_info_search_volume > 0
                  ")
        tb <- bq_project_query("dataforseo-bigquery", sql)
        df <- bq_table_download(tb) 
        cpc <-  df$cpc
        print(cpc)
        }
    locations_cpc <- magic_result_as_dataframe()
    write_csv(locations_cpc, "../raw_data/locations_cpc.csv")
}
#write_locations_cpc()
locations_cpc <- read_csv("../raw_data/locations_cpc.csv")
```


```{r}
write_locations_volume <- function(){
    magic_for(print, silent = TRUE)
    for (code in countries$code){
        sql <- glue("SELECT SUM(keyword_info_search_volume) / 10000 as volume
                    FROM `dataforseo-bigquery.dataforseo_data.keyword_data`
                  WHERE location = {code} 
                  AND keyword_info_search_volume > 0
                  ")
        tb <- bq_project_query("dataforseo-bigquery", sql)
        df <- bq_table_download(tb) 
        volume <-  df$volume * 10000
        print(volume)
        }
    locations_volume <- magic_result_as_dataframe()
    write_csv(locations_volume, "../raw_data/locations_volume.csv")
}
#write_locations_volume()
locations_volume <- read_csv("../raw_data/locations_volume.csv")
```

There is only data for 5 English speaking countries

```{r}
countries <- inner_join(
    locations_volume,
    locations_cpc,
    by = "code") %>% 
    left_join(countries, by = "code") %>% 
    drop_na(volume)

countries$country
```

```{r, countries_volume}
countries %>% 
    mutate(volume_per_pop = volume / pop) %>% 
    mutate(country = case_when(
        country == "United Kingdom" ~ "UK",
        country == "United States" ~ "US",
        T ~ country
    )) %>% 
    ggplot(aes(x = reorder(country, volume_per_pop), y = volume_per_pop)) +
    geom_bar(stat = "identity", fill = bl_dark, width = 0.85, color = "black") +
    scale_y_continuous( expand = c(.001, .001)) +
    theme(panel.grid.major.x = element_blank()) +
    labs(y = "Search volume per person", x = NULL, title = "Total search volume compared to population size")
```



```{r, countries_cpc}
countries %>% 
    mutate(country = case_when(
        country == "United Kingdom" ~ "UK",
        country == "United States" ~ "US",
        T ~ country
    )) %>% 
    ggplot(aes(x = reorder(country, cpc), y = cpc)) +
    geom_bar(stat = "identity", fill = bl_dark, width = 0.85, color = "black") +
    scale_y_continuous( expand = c(.001, .001)) +
    theme(panel.grid.minor.x = element_blank(), 
          panel.grid.major.y = element_blank(), 
          axis.line.y = element_blank()) +
    labs(y = "Mean CPC", x = NULL, title = "Mean CPC by country")
```



```{r sessionInfo}
Sys.time()
git2r::repository()
sessionInfo()
```

</details>
